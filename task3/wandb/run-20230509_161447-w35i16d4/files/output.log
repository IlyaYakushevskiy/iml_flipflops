
Epoch 1: Training Loss: 0.6985, Validation Loss: 0.6585
Epoch 2: Training Loss: 0.6977, Validation Loss: 0.6511
Epoch 3: Training Loss: 0.6932, Validation Loss: 0.6462
Epoch 4: Training Loss: 0.6777, Validation Loss: 0.6402
Epoch 5: Training Loss: 0.6348, Validation Loss: 0.6124
Epoch 6: Training Loss: 0.6260, Validation Loss: 0.5728
Epoch 7: Training Loss: 0.6086, Validation Loss: 0.5551
Epoch 8: Training Loss: 0.6227, Validation Loss: 0.5489
Epoch 9: Training Loss: 0.6170, Validation Loss: 0.5398
Epoch 10: Training Loss: 0.6225, Validation Loss: 0.5378
Epoch 11: Training Loss: 0.6104, Validation Loss: 0.5564
Epoch 12: Training Loss: 0.6027, Validation Loss: 0.5267
Epoch 13: Training Loss: 0.6085, Validation Loss: 0.5373
Epoch 14: Training Loss: 0.5781, Validation Loss: 0.5197
Epoch 15: Training Loss: 0.5717, Validation Loss: 0.5184
Epoch 16: Training Loss: 0.5380, Validation Loss: 0.5132
Epoch 17: Training Loss: 0.5376, Validation Loss: 0.5169
Epoch 18: Training Loss: 0.4975, Validation Loss: 0.5092
Epoch 19: Training Loss: 0.5164, Validation Loss: 0.5064
Epoch 20: Training Loss: 0.4953, Validation Loss: 0.5050
Epoch 21: Training Loss: 0.5075, Validation Loss: 0.5333
Epoch 22: Training Loss: 0.4970, Validation Loss: 0.5200
Epoch 23: Training Loss: 0.4813, Validation Loss: 0.4976
Epoch 24: Training Loss: 0.5262, Validation Loss: 0.5217
Epoch 25: Training Loss: 0.4644, Validation Loss: 0.5011
Epoch 26: Training Loss: 0.4849, Validation Loss: 0.5099
Epoch 27: Training Loss: 0.4723, Validation Loss: 0.4936
Epoch 28: Training Loss: 0.4914, Validation Loss: 0.4939
Epoch 29: Training Loss: 0.5032, Validation Loss: 0.5300
Epoch 30: Training Loss: 0.4912, Validation Loss: 0.4867
Epoch 31: Training Loss: 0.4862, Validation Loss: 0.4893
Epoch 32: Training Loss: 0.5283, Validation Loss: 0.5237
Epoch 33: Training Loss: 0.4947, Validation Loss: 0.4886
Epoch 34: Training Loss: 0.4853, Validation Loss: 0.4904
Epoch 35: Training Loss: 0.4843, Validation Loss: 0.4829
Epoch 36: Training Loss: 0.5197, Validation Loss: 0.5321
Epoch 37: Training Loss: 0.4793, Validation Loss: 0.4954
Epoch 38: Training Loss: 0.5442, Validation Loss: 0.4953
Epoch 39: Training Loss: 0.5346, Validation Loss: 0.4953
Epoch 40: Training Loss: 0.5359, Validation Loss: 0.5295
Epoch 41: Training Loss: 0.5333, Validation Loss: 0.4974
Epoch 42: Training Loss: 0.4685, Validation Loss: 0.5056
Epoch 43: Training Loss: 0.6294, Validation Loss: 0.5355
Epoch 44: Training Loss: 0.4691, Validation Loss: 0.5208
Epoch 45: Training Loss: 0.5806, Validation Loss: 0.5099
Epoch 46: Training Loss: 0.5948, Validation Loss: 0.5150
Epoch 47: Training Loss: 0.6199, Validation Loss: 0.5216
Epoch 48: Training Loss: 0.6562, Validation Loss: 0.5168
Epoch 49: Training Loss: 0.6256, Validation Loss: 0.5491
Epoch 50: Training Loss: 0.5396, Validation Loss: 0.5184
Epoch 51: Training Loss: 0.6589, Validation Loss: 0.5104
Traceback (most recent call last):
  File "/Users/ilya/Desktop/iml_flipflops/task3/sol_Lauriane.py", line 274, in <module>
    model = train_model(train_loader,n_epochs )
  File "/Users/ilya/Desktop/iml_flipflops/task3/sol_Lauriane.py", line 186, in train_model
    output = model(X)
  File "/opt/homebrew/Caskroom/miniforge/base/envs/ml_cv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/ilya/Desktop/iml_flipflops/task3/sol_Lauriane.py", line 141, in forward
    x = F.relu(self.fc1(x))
  File "/opt/homebrew/Caskroom/miniforge/base/envs/ml_cv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/opt/homebrew/Caskroom/miniforge/base/envs/ml_cv/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt